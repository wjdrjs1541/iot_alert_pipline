from kafka import KafkaConsumer, KafkaProducer
import psycopg2
import json
import logging
import binascii
import time
from kafka.admin import KafkaAdminClient, NewTopic
from kafka.errors import TopicAlreadyExistsError

# âœ… Kafka Config
KAFKA_BROKER_PRODUCER = 'kafka1:29092'
KAFKA_BROKER_PROCESSOR = ["kafka1:29092", "kafka2:29093"]
KAFKA_TOPIC = 'iot-sensor-events'
ANOMALY_TOPIC = 'anomaly-topic'

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

def create_topics_if_not_exist(broker, topics):
    admin_client = KafkaAdminClient(bootstrap_servers=broker)
    topic_list = []
    for topic_name in topics:
        topic_list.append(NewTopic(name=topic_name, num_partitions=2, replication_factor=1))
    try:
        admin_client.create_topics(new_topics=topic_list, validate_only=False)
        logger.info(f"âœ… Topic ìƒì„±ë¨: {topics}")
    except TopicAlreadyExistsError:
        logger.info(f"âœ… Topic ì´ë¯¸ ì¡´ì¬: {topics}")
    except Exception as e:
        logger.error(f"ğŸš¨ Topic ìƒì„± ì‹¤íŒ¨: {e}")
    finally:
        admin_client.close()

def get_anomaly_bounds(cursor):
    cursor.execute("SELECT min_temp, max_temp, min_humidity, max_humidity FROM anomaly_range ORDER BY id DESC LIMIT 1")
    result = cursor.fetchone()
    return result if result else (None, None, None, None)


def execute_with_retry(cursor, query, values, retries=3, delay=1):
    for attempt in range(1, retries + 1):
        try:
            cursor.execute(query, values)
            conn.commit()
            return True
        except psycopg2.Error as e:
            logger.error(f"ğŸš¨ DB ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {attempt}/{retries}): {e}")
            time.sleep(delay)
    return False


# PostgreSQL ì—°ê²° (ìµœì´ˆ ì—°ê²°ë„ ì¬ì‹œë„)
while True:
    try:
        conn = psycopg2.connect(host="postgresql", database="iot_data", user="postgres", password="postgres", port="5432")
        cursor = conn.cursor()
        break
    except Exception as e:
        logger.error(f"ğŸš¨ PostgreSQL ì—°ê²° ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... ì—ëŸ¬: {e}")
        time.sleep(3)

# Kafka í† í”½ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±
create_topics_if_not_exist(KAFKA_BROKER_PRODUCER, [KAFKA_TOPIC, ANOMALY_TOPIC])

# Kafka Consumer ì„¤ì •
consumer = KafkaConsumer(
    KAFKA_TOPIC,
    bootstrap_servers=KAFKA_BROKER_PROCESSOR,
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
    auto_offset_reset='earliest',
    enable_auto_commit=True,
    group_id='sensor-consumer-group3',
    session_timeout_ms=10000,   # ì˜µì…˜: ì•ˆì •ì„±
    heartbeat_interval_ms=3000, # ì˜µì…˜: ì•ˆì •ì„±
)
print("test1")
# Kafka Producer ì„¤ì • (ì´ìƒì¹˜ íƒì§€ ì‹œ)
producer = KafkaProducer(
    bootstrap_servers=KAFKA_BROKER_PRODUCER,
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)
print("test2")

# ë©”ì‹œì§€ ì†Œë¹„ ë£¨í”„
for msg in consumer:
    data = msg.value

    # mqtt_msg ëˆ„ë½ ë°©ì–´
    if 'mqtt_msg' not in data:
        logger.error(f"ğŸš¨ mqtt_msg ëˆ„ë½ëœ ë©”ì‹œì§€: {data}")
        continue
    

    try:
        # âœ… mqtt_msg ë””ì½”ë”©
        decoded_msg = binascii.unhexlify(data['mqtt_msg']).decode('ascii').strip()
        temperature_str, humidity_str = decoded_msg.split()
        temperature = float(temperature_str)
        humidity = float(humidity_str)
    except (binascii.Error, UnicodeDecodeError, ValueError, KeyError) as e:
        logger.error(f"ğŸš¨ mqtt_msg ë””ì½”ë”© ì‹¤íŒ¨ ë˜ëŠ” í¬ë§· ì˜¤ë¥˜: {data.get('mqtt_msg')} / ì—ëŸ¬: {e}")
        continue
    
    print("test2")
    # DB ì €ì¥ (ì¬ì‹œë„ 3ë²ˆ)
    if not execute_with_retry(
        cursor,
        "INSERT INTO sensor_data (machine_id, temperature, humidity, sent_time) VALUES (%s, %s, %s, %s)",
        (data['machine_id'], temperature, humidity, data['sent_time']),
        retries=3,
        delay=2
    ):
        logger.error(f"ğŸš¨ DB ì €ì¥ 3íšŒ ì‹¤íŒ¨, í•´ë‹¹ ë°ì´í„° ìŠ¤í‚µ: {data}")
        continue

    # ìµœì‹  ì´ìƒì¹˜ ë²”ìœ„ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        min_temp, max_temp, min_hum, max_hum = get_anomaly_bounds(cursor)
    except Exception as e:
        logger.error(f"ğŸš¨ ì´ìƒì¹˜ ë²”ìœ„ ì¿¼ë¦¬ ì‹¤íŒ¨, ì—ëŸ¬: {e}")
        continue

    if None not in [min_temp, max_temp, min_hum, max_hum]:
        is_temp_anomaly = not (min_temp <= temperature <= max_temp)
        is_hum_anomaly = not (min_hum <= humidity <= max_hum)

        if is_temp_anomaly or is_hum_anomaly:
            logger.warning(f"ğŸš¨ ì´ìƒì¹˜ íƒì§€ë¨! machine_id={data['machine_id']}, temperature={temperature}, humidity={humidity}, sent_time={data['sent_time']}")
            
            # âœ… ì´ìƒì¹˜ Kafka í† í”½ìœ¼ë¡œ ì „ì†¡
            anomaly_payload = {
                "machine_id": data['machine_id'],
                "temperature": temperature,
                "humidity": humidity,
                "sent_time": data['sent_time'],
                "anomaly_type": {
                    "temperature": is_temp_anomaly,
                    "humidity": is_hum_anomaly
                }
            }
            producer.send(ANOMALY_TOPIC, anomaly_payload)
            producer.flush()
        else:
            logger.info(f"âœ… ì •ìƒ ë°ì´í„° ìˆ˜ì‹ : machine_id={data['machine_id']}, temperature={temperature}, humidity={humidity}, sent_time={data['sent_time']}")
    else:
        logger.info(f"â„¹ï¸ ì´ìƒì¹˜ ê¸°ì¤€ ì—†ìŒ. ë°ì´í„° ì €ì¥ë§Œ ìˆ˜í–‰: machine_id={data['machine_id']}, temperature={temperature}, humidity={humidity}, sent_time={data['sent_time']}")
